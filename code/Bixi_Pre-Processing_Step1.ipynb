{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bixi Data Mining Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students: Quan Hao, 11248609; Gabriel Lainesse, 11189782; Chaoyang Zheng, 11249259 \n",
    "\n",
    "Course: Data Mining Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing, appending and merging data. Performing some feature engineering as well as type conversions and data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "from types import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up path variables\n",
    "if 'notebook_path' not in globals():\n",
    "    #if notebook_path does not already exists, create it\n",
    "    notebook_path = os.path.abspath(os.getcwd())\n",
    "else:\n",
    "    #otherwise, change current directory to notebook_path in order to set the other variables\n",
    "    os.chdir(notebook_path)\n",
    "    \n",
    "path_bixi_data = os.path.abspath(r\"Data/Bixi/\")\n",
    "path_weather_data = os.path.abspath(r\"Data/Weather\")\n",
    "path_weather_data2 = os.path.abspath(r\"Data/Weather2\")\n",
    "path_mtl_data = os.path.abspath(r\"Data/Montreal\")\n",
    "path_festival_data = os.path.abspath(r\"Data/Festival\")\n",
    "path_fuel_data = os.path.abspath(r\"Data/Fuel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bixi Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import yearly Bixi Stations tables\n",
    "os.chdir(path_bixi_data)\n",
    "stations_2014 = pd.read_csv(r\"Modified Stations Data/Stations_2014.csv\")\n",
    "stations_2015 = pd.read_csv(r\"Modified Stations Data/Stations_2015.csv\")\n",
    "stations_2016 = pd.read_csv(r\"Modified Stations Data/Stations_2016.csv\")\n",
    "stations_2017 = pd.read_csv(r\"Modified Stations Data/Stations_2017.csv\")\n",
    "stations_2018 = pd.read_csv(r\"Modified Stations Data/Stations_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>great_park</th>\n",
       "      <th>affectation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6209</td>\n",
       "      <td>Milton / Clark</td>\n",
       "      <td>45.512520</td>\n",
       "      <td>-73.570620</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6436</td>\n",
       "      <td>Côte St-Antoine / Clarke</td>\n",
       "      <td>45.486452</td>\n",
       "      <td>-73.595234</td>\n",
       "      <td>Westmount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6214</td>\n",
       "      <td>Square St-Louis</td>\n",
       "      <td>45.517350</td>\n",
       "      <td>-73.569060</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residentiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6248</td>\n",
       "      <td>St-Dominique / Rachel</td>\n",
       "      <td>45.518593</td>\n",
       "      <td>-73.581566</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mixte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6164</td>\n",
       "      <td>Chambord / Laurier</td>\n",
       "      <td>45.532955</td>\n",
       "      <td>-73.584194</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residentiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  code                      name   latitude  longitude  \\\n",
       "0           0  6209            Milton / Clark  45.512520 -73.570620   \n",
       "1           1  6436  Côte St-Antoine / Clarke  45.486452 -73.595234   \n",
       "2           2  6214           Square St-Louis  45.517350 -73.569060   \n",
       "3           3  6248     St-Dominique / Rachel  45.518593 -73.581566   \n",
       "4           4  6164        Chambord / Laurier  45.532955 -73.584194   \n",
       "\n",
       "            neighborhood great_park  affectation  \n",
       "0  Le Plateau-Mont-Royal        NaN        mixte  \n",
       "1              Westmount        NaN          NaN  \n",
       "2  Le Plateau-Mont-Royal        NaN  residentiel  \n",
       "3  Le Plateau-Mont-Royal        NaN        mixte  \n",
       "4  Le Plateau-Mont-Royal        NaN  residentiel  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_2014.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the Bixi Bike Rental Activity with the Stations Data and Appending them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bixi Bike Rental Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Mass Append Table Function:\n",
    "def mass_append(df_list):\n",
    "    \"\"\" \n",
    "    mass_append(df_list)\n",
    "    \n",
    "    Description:\n",
    "        This function appends together all DataFrames withina list.\n",
    "    \n",
    "    Argument(s): \n",
    "        df_list : List of pandas DataFrame objects. \n",
    "    \"\"\"\n",
    "    # Instantiate empty DataFrame\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    for df in df_list:\n",
    "        # Append each table one by one\n",
    "        output_df = output_df.append(df)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bixi Bike Rental Activity for each year\n",
    "# For each year, store filenames in a list\n",
    "files_rentals_2014 = [x for x in os.listdir() if \"OD_2014\" in x]\n",
    "files_rentals_2015 = [x for x in os.listdir() if \"OD_2015\" in x]\n",
    "files_rentals_2016 = [x for x in os.listdir() if \"OD_2016\" in x]\n",
    "files_rentals_2017 = [x for x in os.listdir() if \"OD_2017\" in x]\n",
    "files_rentals_2018 = [x for x in os.listdir() if \"OD_2018\" in x]\n",
    "files_rentals_all = [(files_rentals_2014, stations_2014), \n",
    "                     (files_rentals_2015, stations_2015), \n",
    "                     (files_rentals_2016, stations_2016), \n",
    "                     (files_rentals_2017, stations_2017),\n",
    "                     (files_rentals_2018, stations_2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing current directory to bixi data\n",
    "os.chdir(path_bixi_data)\n",
    "# Reading as DataFrame and then appending all DataFrames from 2014 trip history csv files\n",
    "df_rentals_2014 = mass_append([pd.read_csv(x) for x in files_rentals_2014])\n",
    "\n",
    "# Merging the appended trip history to the stations data (for starting stations).\n",
    "df_rentals_2014 = df_rentals_2014.merge(stations_2014, how='left', \n",
    "                                        left_on='start_station_code', right_on='code')\n",
    "\n",
    "# Renaming columns\n",
    "df_rentals_2014.rename({'code':'start_code', \n",
    "                        'name':'start_name', \n",
    "                        'latitude':'start_latitude', \n",
    "                        'longitude':'start_longitude',\n",
    "                        'neighborhood':'start_neighborhood',\n",
    "                        'great_park':'start_great_park',\n",
    "                        'affectation':'start_affectation'}, axis='columns', inplace=True)\n",
    "\n",
    "# Merging the appended trip history to the stations data (for ending stations).\n",
    "df_rentals_2014 = df_rentals_2014.merge(stations_2014, how='left', \n",
    "                                        left_on='end_station_code', right_on='code')\n",
    "\n",
    "# Renaming columns\n",
    "df_rentals_2014.rename({'code':'end_code', \n",
    "                        'name':'end_name', \n",
    "                        'latitude':'end_latitude', \n",
    "                        'longitude':'end_longitude',\n",
    "                        'neighborhood':'end_neighborhood',\n",
    "                        'great_park':'end_great_park',\n",
    "                        'affectation':'end_affectation'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for 2015 as was done for the previous years.\n",
    "df_rentals_2015 = mass_append([pd.read_csv(x) for x in files_rentals_2015])\n",
    "df_rentals_2015 = df_rentals_2015.merge(stations_2015, how='left', \n",
    "                                        left_on='start_station_code', right_on='code')\n",
    "df_rentals_2015.rename({'code':'start_code', \n",
    "                        'name':'start_name', \n",
    "                        'latitude':'start_latitude', \n",
    "                        'longitude':'start_longitude',\n",
    "                        'neighborhood':'start_neighborhood',\n",
    "                        'great_park':'start_great_park',\n",
    "                        'affectation':'start_affectation'}, axis='columns', inplace=True)\n",
    "df_rentals_2015 = df_rentals_2015.merge(stations_2015, how='left', \n",
    "                                        left_on='end_station_code', right_on='code')\n",
    "df_rentals_2015.rename({'code':'end_code', \n",
    "                        'name':'end_name', \n",
    "                        'latitude':'end_latitude', \n",
    "                        'longitude':'end_longitude',\n",
    "                        'neighborhood':'end_neighborhood',\n",
    "                        'great_park':'end_great_park',\n",
    "                        'affectation':'end_affectation'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for 2016 as was done for the previous years.\n",
    "df_rentals_2016 = mass_append([pd.read_csv(x) for x in files_rentals_2016])\n",
    "df_rentals_2016 = df_rentals_2016.merge(stations_2016, how='left', \n",
    "                                        left_on='start_station_code', right_on='code')\n",
    "df_rentals_2016.rename({'code':'start_code', \n",
    "                        'name':'start_name', \n",
    "                        'latitude':'start_latitude', \n",
    "                        'longitude':'start_longitude',\n",
    "                        'neighborhood':'start_neighborhood',\n",
    "                        'great_park':'start_great_park',\n",
    "                        'affectation':'start_affectation'}, axis='columns', inplace=True)\n",
    "df_rentals_2016 = df_rentals_2016.merge(stations_2016, how='left', \n",
    "                                        left_on='end_station_code', right_on='code')\n",
    "df_rentals_2016.rename({'code':'end_code', \n",
    "                        'name':'end_name', \n",
    "                        'latitude':'end_latitude', \n",
    "                        'longitude':'end_longitude',\n",
    "                        'neighborhood':'end_neighborhood',\n",
    "                        'great_park':'end_great_park',\n",
    "                        'affectation':'end_affectation'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for 2017 as was done for the previous years.\n",
    "df_rentals_2017 = mass_append([pd.read_csv(x) for x in files_rentals_2017])\n",
    "df_rentals_2017 = df_rentals_2017.merge(stations_2017, how='left', \n",
    "                                        left_on='start_station_code', right_on='code')\n",
    "df_rentals_2017.rename({'code':'start_code', \n",
    "                        'name':'start_name', \n",
    "                        'latitude':'start_latitude', \n",
    "                        'longitude':'start_longitude',\n",
    "                        'neighborhood':'start_neighborhood',\n",
    "                        'great_park':'start_great_park',\n",
    "                        'affectation':'start_affectation'}, axis='columns', inplace=True)\n",
    "df_rentals_2017 = df_rentals_2017.merge(stations_2017, how='left', \n",
    "                                        left_on='end_station_code', right_on='code')\n",
    "df_rentals_2017.rename({'code':'end_code', \n",
    "                        'name':'end_name', \n",
    "                        'latitude':'end_latitude', \n",
    "                        'longitude':'end_longitude',\n",
    "                        'neighborhood':'end_neighborhood',\n",
    "                        'great_park':'end_great_park',\n",
    "                        'affectation':'end_affectation'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for 2018 as was done for the previous years.\n",
    "df_rentals_2018 = mass_append([pd.read_csv(x) for x in files_rentals_2018])\n",
    "df_rentals_2018 = df_rentals_2018.merge(stations_2018, how='left', \n",
    "                                        left_on='start_station_code', right_on='code')\n",
    "df_rentals_2018.rename({'code':'start_code', \n",
    "                        'name':'start_name', \n",
    "                        'latitude':'start_latitude', \n",
    "                        'longitude':'start_longitude',\n",
    "                        'neighborhood':'start_neighborhood',\n",
    "                        'great_park':'start_great_park',\n",
    "                        'affectation':'start_affectation'}, axis='columns', inplace=True)\n",
    "df_rentals_2018 = df_rentals_2018.merge(stations_2018, how='left', \n",
    "                                        left_on='end_station_code', right_on='code')\n",
    "df_rentals_2018.rename({'code':'end_code', \n",
    "                        'name':'end_name', \n",
    "                        'latitude':'end_latitude', \n",
    "                        'longitude':'end_longitude',\n",
    "                        'neighborhood':'end_neighborhood',\n",
    "                        'great_park':'end_great_park',\n",
    "                        'affectation':'end_affectation'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Final Output to either the full dataset or just one year:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to performance constraints, we chose to build our model using only one year of the dataset. The two cells below allow us to either export everything, or export only a single year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export only one year. Uncomment to perform, comment out to prevent execution.\n",
    "df_rentals = df_rentals_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all data. Uncomment to perform, comment out to prevent execution.\n",
    "#df_rentals = mass_append([df_rentals_2014, df_rentals_2015, df_rentals_2016, \n",
    "#                       df_rentals_2017, df_rentals_2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting non-merged DataFrames to save memory\n",
    "try:\n",
    "    del df_rentals_2014\n",
    "    del df_rentals_2015\n",
    "    del df_rentals_2016\n",
    "    del df_rentals_2017\n",
    "    del df_rentals_2018\n",
    "    del stations_2014\n",
    "    del stations_2015\n",
    "    del stations_2016\n",
    "    del stations_2017\n",
    "    del stations_2018\n",
    "except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Type Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coercing start_date and end_date to datetime type.\n",
    "df_rentals['start_date'] = pd.to_datetime(df_rentals['start_date'])\n",
    "df_rentals['end_date'] = pd.to_datetime(df_rentals['end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two new variables containing the nearest hour from 'start_date' and 'end_date'\n",
    "# in order to create categories for the time of the day\n",
    "df_rentals = df_rentals.assign(start_date_hour = df_rentals['start_date'].dt.hour)\n",
    "df_rentals = df_rentals.assign(end_date_hour = df_rentals['end_date'].dt.hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and merging Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version of weather data (from Weatherstats.ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the first version of weather data\n",
    "os.chdir(path_weather_data)\n",
    "weather = pd.read_csv(\"weatherstats_montreal_hourly.csv\", parse_dates=[\"date_time_local\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version of weather data (from Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_weather_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weather descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Weather descriptions and keep only Montreal\n",
    "w2_desc = pd.read_csv(\"weather_description.csv\", parse_dates=['datetime'])\n",
    "w2_desc = w2_desc.filter(axis=1,items=['datetime','Montreal'])\n",
    "w2_desc = w2_desc.rename({'Montreal':'Weather Condition'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Humidity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Humidity and keep only Montreal\n",
    "w2_humid = pd.read_csv(\"humidity.csv\", parse_dates=['datetime'])\n",
    "w2_humid = w2_humid.filter(axis=1, items=['datetime', 'Montreal']).rename({'Montreal':'Humidity'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atmospheric Pressure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Atmospheric Pressure and keep only Montreal\n",
    "w2_pressure = pd.read_csv(\"pressure.csv\", parse_dates=['datetime'])\n",
    "w2_pressure = w2_pressure.filter(axis=1, items=['datetime', 'Montreal']).rename({'Montreal':'Pressure'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wind Speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Wind Speed and keep only Montreal\n",
    "w2_wspeed = pd.read_csv(\"wind_speed.csv\", parse_dates=['datetime'])\n",
    "w2_wspeed = w2_wspeed.filter(axis=1, items=['datetime', 'Montreal']).rename({'Montreal':'Wind Speed'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Temperature and keep only Montreal\n",
    "w2_temp = pd.read_csv(\"temperature.csv\", parse_dates=['datetime'])\n",
    "w2_temp = w2_temp.filter(axis=1, items=['datetime', 'Montreal']).rename({'Montreal':'Temperature'}, axis=1)\n",
    "# Transforming Kelvin measures into Celcius\n",
    "w2_temp['Temperature'] = w2_temp['Temperature'] - 273.15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging all weather metrics together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = w2_desc.merge(w2_humid, how='left', left_on='datetime', right_on='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = weather2.merge(w2_pressure, how='left', left_on='datetime', right_on='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = weather2.merge(w2_wspeed, how='left', left_on='datetime', right_on='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = weather2.merge(w2_temp, how='left', left_on='datetime', right_on='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Weather Condition</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>91.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.684650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>87.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.697790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>84.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.710929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime Weather Condition  Humidity  Pressure  Wind Speed  \\\n",
       "0 2012-10-01 12:00:00               NaN       NaN       NaN         NaN   \n",
       "1 2012-10-01 13:00:00   overcast clouds      93.0    1001.0         4.0   \n",
       "2 2012-10-01 14:00:00      sky is clear      91.0     986.0         4.0   \n",
       "3 2012-10-01 15:00:00      sky is clear      87.0     945.0         4.0   \n",
       "4 2012-10-01 16:00:00      sky is clear      84.0     904.0         4.0   \n",
       "\n",
       "   Temperature  \n",
       "0          NaN  \n",
       "1    12.680000  \n",
       "2    12.684650  \n",
       "3    12.697790  \n",
       "4    12.710929  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Activity and Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose weather data, version 1 or 2\n",
    "weather_version = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns from weather data version 1\n",
    "weather.drop(['health_index', 'cloud_cover_4', 'cloud_cover_10', 'wind_dir', 'wind_dir_10s', 'wind_gust',\n",
    "              'solar_radiation'], \n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort trip history by start_date in order to merge with weather data\n",
    "df_rentals.sort_values(by='start_date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trip history with weather data depending on the version of weather data used\n",
    "if weather_version == 1:\n",
    "    merged_data = pd.merge_asof(df_rentals, weather, left_on='start_date', \n",
    "                                        right_on='date_time_local', direction= 'nearest')\n",
    "elif weather_version == 2:\n",
    "       merged_data = pd.merge_asof(df_rentals, weather2, left_on='start_date', \n",
    "                                           right_on='datetime', direction= 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting weather data to free up memory\n",
    "del weather\n",
    "del weather2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Festival Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change current working directory\n",
    "os.chdir(path_festival_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import festival data\n",
    "festival = pd.read_csv(\"csv_dataset_holiday_festival.csv\", parse_dates=['date'], encoding = \"gb2312\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary column\n",
    "festival.drop(['weenkend'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>festival_1</th>\n",
       "      <th>festivial_name_1</th>\n",
       "      <th>latitude_1</th>\n",
       "      <th>longitude_1</th>\n",
       "      <th>festival_2</th>\n",
       "      <th>festival_name_2</th>\n",
       "      <th>latitude_2</th>\n",
       "      <th>longitude_2</th>\n",
       "      <th>statutory_holiday</th>\n",
       "      <th>statutory_holiday_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  festival_1 festivial_name_1  latitude_1  longitude_1  \\\n",
       "0 2014-04-15         0.0              NaN         NaN          NaN   \n",
       "1 2014-04-16         0.0              NaN         NaN          NaN   \n",
       "2 2014-04-17         0.0              NaN         NaN          NaN   \n",
       "3 2014-04-18         0.0              NaN         NaN          NaN   \n",
       "4 2014-04-19         0.0              NaN         NaN          NaN   \n",
       "\n",
       "   festival_2 festival_name_2  latitude_2  longitude_2  statutory_holiday  \\\n",
       "0         0.0             NaN         NaN          NaN                0.0   \n",
       "1         0.0             NaN         NaN          NaN                0.0   \n",
       "2         0.0             NaN         NaN          NaN                0.0   \n",
       "3         0.0             NaN         NaN          NaN                1.0   \n",
       "4         0.0             NaN         NaN          NaN                0.0   \n",
       "\n",
       "  statutory_holiday_name  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3            good friday  \n",
       "4                    NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting data\n",
    "festival.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only rows with relevant information\n",
    "# (removing all non-positive values regarding if there was a festival or a statutory holiday)\n",
    "festival = festival[(festival['festival_1'] == 1.0) | (festival['festival_2'] == 1.0) | (festival['statutory_holiday'] == 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a binary variable 'has_festival'\n",
    "festival['has_festival'] = (festival['festival_1'] == 1.0) | (festival['festival_2'] == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coercing 'statutory_holiday' into a binary variable\n",
    "festival['statutory_holiday'] = (festival['statutory_holiday'] == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing now unnecessary variables\n",
    "festival.drop(['festival_1', 'festival_2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>festivial_name_1</th>\n",
       "      <th>latitude_1</th>\n",
       "      <th>longitude_1</th>\n",
       "      <th>festival_name_2</th>\n",
       "      <th>latitude_2</th>\n",
       "      <th>longitude_2</th>\n",
       "      <th>statutory_holiday</th>\n",
       "      <th>statutory_holiday_name</th>\n",
       "      <th>has_festival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>good friday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>easter monday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014-05-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>victoria day/national patriots day</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2014-06-07</td>\n",
       "      <td>2014 Canadian Grand Prix</td>\n",
       "      <td>45.503231</td>\n",
       "      <td>-73.52669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2014-06-08</td>\n",
       "      <td>2014 Canadian Grand Prix</td>\n",
       "      <td>45.503231</td>\n",
       "      <td>-73.52669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          festivial_name_1  latitude_1  longitude_1  \\\n",
       "3  2014-04-18                       NaN         NaN          NaN   \n",
       "6  2014-04-21                       NaN         NaN          NaN   \n",
       "34 2014-05-19                       NaN         NaN          NaN   \n",
       "53 2014-06-07  2014 Canadian Grand Prix   45.503231    -73.52669   \n",
       "54 2014-06-08  2014 Canadian Grand Prix   45.503231    -73.52669   \n",
       "\n",
       "   festival_name_2  latitude_2  longitude_2  statutory_holiday  \\\n",
       "3              NaN         NaN          NaN               True   \n",
       "6              NaN         NaN          NaN               True   \n",
       "34             NaN         NaN          NaN               True   \n",
       "53             NaN         NaN          NaN              False   \n",
       "54             NaN         NaN          NaN              False   \n",
       "\n",
       "                statutory_holiday_name  has_festival  \n",
       "3                          good friday         False  \n",
       "6                       easter monday          False  \n",
       "34  victoria day/national patriots day         False  \n",
       "53                                 NaN          True  \n",
       "54                                 NaN          True  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the data\n",
    "festival.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Festival data with Merged Activity and Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the festival data with the dataset\n",
    "merged_data = merged_data.merge(festival, how='left', left_on='start_date', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['start_date', 'start_station_code', 'end_date', 'end_station_code',\n",
       "       'duration_sec', 'is_member', 'Unnamed: 0_x', 'start_code', 'start_name',\n",
       "       'start_latitude', 'start_longitude', 'start_neighborhood',\n",
       "       'start_great_park', 'start_affectation', 'Unnamed: 0_y', 'end_code',\n",
       "       'end_name', 'end_latitude', 'end_longitude', 'end_neighborhood',\n",
       "       'end_great_park', 'end_affectation', 'start_date_hour', 'end_date_hour',\n",
       "       'datetime', 'Weather Condition', 'Humidity', 'Pressure', 'Wind Speed',\n",
       "       'Temperature', 'date', 'festivial_name_1', 'latitude_1', 'longitude_1',\n",
       "       'festival_name_2', 'latitude_2', 'longitude_2', 'statutory_holiday',\n",
       "       'statutory_holiday_name', 'has_festival'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting columns\n",
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping superflous columns:\n",
    "merged_data.drop(['Unnamed: 0_x', 'Unnamed: 0_y',\n",
    "                    'start_station_code', 'end_station_code'],\n",
    "                  axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "merged_data.rename({'latitude_1':'festival1_lat',\n",
    "                        'longitude_1':'festival1_long', \n",
    "                        'latitude_2':'festival2_lat', \n",
    "                        'longitude_2':'festival2_long'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DateTime & Route Feature Engineering & Changing Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new features based on datetime values and combined values for the start station and the end station (considered to be a 'route')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coercing 'start_date' and 'end_date' into the datetime data type\n",
    "merged_data['start_datetime'] = pd.to_datetime(merged_data['start_date'])\n",
    "merged_data['end_datetime'] = pd.to_datetime(merged_data['end_date'])\n",
    "\n",
    "# Creating two new variables, 'start_date' and 'end_date' to hold only the date portion of the datetime columns\n",
    "merged_data['start_date'] = pd.to_datetime(merged_data['start_datetime'].dt.date)\n",
    "merged_data['end_date'] = pd.to_datetime(merged_data['end_datetime'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two new variables, 'start_month' and 'end_month' to hold only the month portion of the datetime columns\n",
    "merged_data['start_month'] = merged_data['start_datetime'].dt.month\n",
    "merged_data['end_month'] = merged_data['end_datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two new variables, 'start_dayofyear' and 'end_dayofyear' to hold only the dayofyear portion of the datetime columns\n",
    "merged_data['start_daynum'] = merged_data['start_datetime'].dt.dayofyear\n",
    "merged_data['end_daynum'] = merged_data['end_datetime'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two new variables, 'start_weekofyear' and 'end_wekofyear' to hold only the weekofyear portion of the datetime columns\n",
    "merged_data['start_weeknum'] = merged_data['start_datetime'].dt.weekofyear\n",
    "merged_data['end_weeknum'] = merged_data['end_datetime'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two new variables, 'start_weekday' and 'end_weekday' to hold only the day of the week portion of the datetime columns\n",
    "merged_data['start_weekday'] = merged_data['start_datetime'].dt.dayofweek\n",
    "merged_data['end_weekday'] = merged_data['end_datetime'].dt.dayofweek\n",
    "# Monday = 0, Tuesday = 1, ..., Saturday = 5, Sunday = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding route code and name\n",
    "merged_data['route'] = merged_data['start_code'].map(str) + merged_data['end_code'].map(str)\n",
    "merged_data['route_name'] = merged_data['start_name'] + '-' + merged_data['end_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding period of the day : categorical variable for the time of day : with more categories\n",
    "def hour_mapping_large(hour):\n",
    "    if hour < 3:\n",
    "        return 'Late Night'\n",
    "    elif hour < 6:\n",
    "        return 'Early Morning'        \n",
    "    elif hour < 9:\n",
    "        return 'Morning'\n",
    "    elif hour < 11:\n",
    "        return 'Late Morning'\n",
    "    elif hour < 13:\n",
    "        return 'Noon'\n",
    "    elif hour < 15:\n",
    "        return 'Early Afternoon'\n",
    "    elif hour < 17:\n",
    "        return 'Late Afternoon'\n",
    "    elif hour < 20:\n",
    "        return 'Evening'\n",
    "    elif hour < 24:\n",
    "        return 'Early Night'\n",
    "    else:\n",
    "        return 'Error'\n",
    "merged_data['period_of_day_large'] = merged_data['start_date_hour'].apply(hour_mapping_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding period of the day : categorical variable for the time of day : with fewer categories\n",
    "def hour_mapping_small(hour):\n",
    "    if hour < 6:\n",
    "        return 'Early Morning'\n",
    "    elif hour < 11:\n",
    "        return 'Morning'        \n",
    "    elif hour < 14:\n",
    "        return 'Noon'\n",
    "    elif hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif hour < 22:\n",
    "        return 'Evening'\n",
    "    elif hour < 24:\n",
    "        return 'Night'\n",
    "    else:\n",
    "        return 'Error'\n",
    "merged_data['period_of_day_small'] = merged_data['start_date_hour'].apply(hour_mapping_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering : Adding Fuel Prices Data from Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing fuel data\n",
    "os.chdir(path_fuel_data)\n",
    "fuel = pd.read_csv(\"fueltypesall.csv\", parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean fuel price in Toronto\n",
    "fuel['Toronto_mean'] = (fuel['Toronto West/Ouest'] + fuel['Toronto East/Est']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only prices for Regular Unleaded Gasoline\n",
    "fuel = fuel[fuel['Fuel Type'] == \"Regular Unleaded Gasoline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a datetime index in a new dataframe in order to fill it with the nearest gas price value\n",
    "fuel_dates = pd.DataFrame(index=pd.date_range(start=pd.to_datetime(\"2014-04-15\"), end=pd.to_datetime(\"2018-10-31\")))\n",
    "fuel_dates['date'] = pd.to_datetime(fuel_dates.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging fuel dates with fuel prices\n",
    "fuel_dates_merged = fuel_dates.merge(fuel, how='left', left_on='date', right_on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering only on required columns\n",
    "fuel_dates_merged = fuel_dates_merged.filter(['price', 'date', 'Toronto_mean'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values forward\n",
    "fuel_dates_merged.fillna(method='ffill',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values backward (for the first week)\n",
    "fuel_dates_merged.fillna(method='bfill',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Toronto_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>138.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>138.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>138.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>138.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>138.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Toronto_mean\n",
       "0 2014-04-15         138.4\n",
       "1 2014-04-16         138.4\n",
       "2 2014-04-17         138.4\n",
       "3 2014-04-18         138.4\n",
       "4 2014-04-19         138.4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting dataframe\n",
    "fuel_dates_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding fuel data to the dataset\n",
    "merged_data = merged_data.merge(fuel_dates_merged, how='left', left_on='start_date', right_on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pre-Processing for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate columns\n",
    "merged_data.drop(['date_x', 'date_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the date time column that came from merging weather data\n",
    "if weather_version == 2:\n",
    "    merged_data.drop(['datetime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the Fuel Price column\n",
    "merged_data.rename({\"Toronto_mean\":\"Fuel Price\"}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an affectation feature for routes\n",
    "merged_data['route_affectations'] = merged_data['start_affectation'].map(str) + \"-\" + merged_data['end_affectation'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a neighborhood feature for routes\n",
    "merged_data['route_neighborhood'] = merged_data['start_neighborhood'].map(str) + \"-\" + merged_data['end_neighborhood'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a great park feature for routes\n",
    "merged_data['route_great_park'] = merged_data['start_great_park'].map(str) + \"-\" + merged_data['end_great_park'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>start_code</th>\n",
       "      <th>start_name</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>start_neighborhood</th>\n",
       "      <th>start_great_park</th>\n",
       "      <th>...</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>route</th>\n",
       "      <th>route_name</th>\n",
       "      <th>period_of_day_large</th>\n",
       "      <th>period_of_day_small</th>\n",
       "      <th>Fuel Price</th>\n",
       "      <th>route_affectations</th>\n",
       "      <th>route_neighborhood</th>\n",
       "      <th>route_great_park</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>1841</td>\n",
       "      <td>1</td>\n",
       "      <td>7060</td>\n",
       "      <td>de l'Église / de Verdun</td>\n",
       "      <td>45.463001</td>\n",
       "      <td>-73.571569</td>\n",
       "      <td>Verdun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>70607060</td>\n",
       "      <td>de l'Église / de Verdun-de l'Église / de Verdun</td>\n",
       "      <td>Late Night</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>114.55</td>\n",
       "      <td>residentiel-residentiel</td>\n",
       "      <td>Verdun-Verdun</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "      <td>6173</td>\n",
       "      <td>Berri / Cherrier</td>\n",
       "      <td>45.519088</td>\n",
       "      <td>-73.569509</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61736173</td>\n",
       "      <td>Berri / Cherrier-Berri / Cherrier</td>\n",
       "      <td>Late Night</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>114.55</td>\n",
       "      <td>institution-institution</td>\n",
       "      <td>Le Plateau-Mont-Royal-Le Plateau-Mont-Royal</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>6203</td>\n",
       "      <td>Hutchison / Sherbrooke</td>\n",
       "      <td>45.507810</td>\n",
       "      <td>-73.572080</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>62036204</td>\n",
       "      <td>Hutchison / Sherbrooke-Milton / Durocher</td>\n",
       "      <td>Late Night</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>114.55</td>\n",
       "      <td>mixte-residentiel</td>\n",
       "      <td>Le Plateau-Mont-Royal-Le Plateau-Mont-Royal</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>6104</td>\n",
       "      <td>Wolfe / René-Lévesque</td>\n",
       "      <td>45.516818</td>\n",
       "      <td>-73.554188</td>\n",
       "      <td>Ville-Marie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61046114</td>\n",
       "      <td>Wolfe / René-Lévesque-Métro Papineau (Cartier ...</td>\n",
       "      <td>Late Night</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>114.55</td>\n",
       "      <td>mixte-mixte</td>\n",
       "      <td>Ville-Marie-Ville-Marie</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>569</td>\n",
       "      <td>1</td>\n",
       "      <td>6174</td>\n",
       "      <td>Roy / St-Denis</td>\n",
       "      <td>45.519080</td>\n",
       "      <td>-73.572700</td>\n",
       "      <td>Le Plateau-Mont-Royal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61746174</td>\n",
       "      <td>Roy / St-Denis-Roy / St-Denis</td>\n",
       "      <td>Late Night</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>114.55</td>\n",
       "      <td>mixte-mixte</td>\n",
       "      <td>Le Plateau-Mont-Royal-Le Plateau-Mont-Royal</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_date   end_date  duration_sec  is_member  start_code  \\\n",
       "0 2017-04-15 2017-04-15          1841          1        7060   \n",
       "1 2017-04-15 2017-04-15           553          1        6173   \n",
       "2 2017-04-15 2017-04-15           195          1        6203   \n",
       "3 2017-04-15 2017-04-15           285          1        6104   \n",
       "4 2017-04-15 2017-04-15           569          1        6174   \n",
       "\n",
       "                start_name  start_latitude  start_longitude  \\\n",
       "0  de l'Église / de Verdun       45.463001       -73.571569   \n",
       "1         Berri / Cherrier       45.519088       -73.569509   \n",
       "2   Hutchison / Sherbrooke       45.507810       -73.572080   \n",
       "3    Wolfe / René-Lévesque       45.516818       -73.554188   \n",
       "4           Roy / St-Denis       45.519080       -73.572700   \n",
       "\n",
       "      start_neighborhood start_great_park        ...        start_weekday  \\\n",
       "0                 Verdun              NaN        ...                    5   \n",
       "1  Le Plateau-Mont-Royal              NaN        ...                    5   \n",
       "2  Le Plateau-Mont-Royal              NaN        ...                    5   \n",
       "3            Ville-Marie              NaN        ...                    5   \n",
       "4  Le Plateau-Mont-Royal              NaN        ...                    5   \n",
       "\n",
       "   end_weekday     route                                         route_name  \\\n",
       "0            5  70607060    de l'Église / de Verdun-de l'Église / de Verdun   \n",
       "1            5  61736173                  Berri / Cherrier-Berri / Cherrier   \n",
       "2            5  62036204           Hutchison / Sherbrooke-Milton / Durocher   \n",
       "3            5  61046114  Wolfe / René-Lévesque-Métro Papineau (Cartier ...   \n",
       "4            5  61746174                      Roy / St-Denis-Roy / St-Denis   \n",
       "\n",
       "   period_of_day_large period_of_day_small Fuel Price  \\\n",
       "0           Late Night       Early Morning     114.55   \n",
       "1           Late Night       Early Morning     114.55   \n",
       "2           Late Night       Early Morning     114.55   \n",
       "3           Late Night       Early Morning     114.55   \n",
       "4           Late Night       Early Morning     114.55   \n",
       "\n",
       "        route_affectations                           route_neighborhood  \\\n",
       "0  residentiel-residentiel                                Verdun-Verdun   \n",
       "1  institution-institution  Le Plateau-Mont-Royal-Le Plateau-Mont-Royal   \n",
       "2        mixte-residentiel  Le Plateau-Mont-Royal-Le Plateau-Mont-Royal   \n",
       "3              mixte-mixte                      Ville-Marie-Ville-Marie   \n",
       "4              mixte-mixte  Le Plateau-Mont-Royal-Le Plateau-Mont-Royal   \n",
       "\n",
       "   route_great_park  \n",
       "0           nan-nan  \n",
       "1           nan-nan  \n",
       "2           nan-nan  \n",
       "3           nan-nan  \n",
       "4           nan-nan  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the final dataset\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4740357, 52)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the shape of the final dataset\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/gabriel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning:\n",
      "\n",
      "\n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['start_name', 'start_neighborhood', 'start_great_park', 'start_affectation', 'end_name', 'end_neighborhood', 'end_great_park', 'end_affectation', 'Weather Condition', 'festivial_name_1', 'festival_name_2', 'statutory_holiday', 'statutory_holiday_name', 'has_festival', 'route', 'route_name', 'period_of_day_large', 'period_of_day_small', 'route_affectations', 'route_neighborhood', 'route_great_park']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Saving to HDF, the format which has the best read time among all other formats we tried.\n",
    "merged_data.to_hdf(\"dataset_2017.hdf\",key=\"dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
