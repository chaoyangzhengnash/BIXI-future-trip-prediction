{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FnMozcvgsLn3"
   },
   "source": [
    "# Bixi Data Mining Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-x0hb3pbsmw6"
   },
   "source": [
    "Students: Quan Hao, 11248609; Gabriel Lainesse, 11189782; Chaoyang Zheng, 11249259 \n",
    "\n",
    "Course: Data Mining Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hP9Y4XvIsowW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file = r\"/Users/gabriel/dataset_2017.hdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_hdf(path_or_buf=hdf_file,key=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4740357 entries, 0 to 4740356\n",
      "Data columns (total 52 columns):\n",
      "start_date                datetime64[ns]\n",
      "end_date                  datetime64[ns]\n",
      "duration_sec              int64\n",
      "is_member                 int64\n",
      "start_code                int64\n",
      "start_name                object\n",
      "start_latitude            float64\n",
      "start_longitude           float64\n",
      "start_neighborhood        object\n",
      "start_great_park          object\n",
      "start_affectation         object\n",
      "end_code                  int64\n",
      "end_name                  object\n",
      "end_latitude              float64\n",
      "end_longitude             float64\n",
      "end_neighborhood          object\n",
      "end_great_park            object\n",
      "end_affectation           object\n",
      "start_date_hour           int64\n",
      "end_date_hour             int64\n",
      "Weather Condition         object\n",
      "Humidity                  float64\n",
      "Pressure                  float64\n",
      "Wind Speed                float64\n",
      "Temperature               float64\n",
      "festivial_name_1          object\n",
      "festival1_lat             float64\n",
      "festival1_long            float64\n",
      "festival_name_2           object\n",
      "festival2_lat             float64\n",
      "festival2_long            float64\n",
      "statutory_holiday         object\n",
      "statutory_holiday_name    object\n",
      "has_festival              object\n",
      "start_datetime            datetime64[ns]\n",
      "end_datetime              datetime64[ns]\n",
      "start_month               int64\n",
      "end_month                 int64\n",
      "start_daynum              int64\n",
      "end_daynum                int64\n",
      "start_weeknum             int64\n",
      "end_weeknum               int64\n",
      "start_weekday             int64\n",
      "end_weekday               int64\n",
      "route                     object\n",
      "route_name                object\n",
      "period_of_day_large       object\n",
      "period_of_day_small       object\n",
      "Fuel Price                float64\n",
      "route_affectations        object\n",
      "route_neighborhood        object\n",
      "route_great_park          object\n",
      "dtypes: datetime64[ns](4), float64(13), int64(14), object(21)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "# Checking dataset content and datatypes\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing for Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further data pre-processing is required in order to build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "broken clouds                   1383352\n",
       "few clouds                      1011042\n",
       "overcast clouds                  648132\n",
       "scattered clouds                 482542\n",
       "mist                             341285\n",
       "sky is clear                     332341\n",
       "light intensity shower rain      163973\n",
       "light rain                       127779\n",
       "fog                               84218\n",
       "proximity shower rain             81129\n",
       "thunderstorm with light rain      23908\n",
       "haze                              16603\n",
       "proximity thunderstorm            11421\n",
       "thunderstorm                       8823\n",
       "light intensity drizzle            7795\n",
       "thunderstorm with rain             5089\n",
       "moderate rain                      3859\n",
       "light shower snow                  2380\n",
       "light intensity drizzle rain       2286\n",
       "thunderstorm with heavy rain       2038\n",
       "shower rain                         362\n",
       "Name: Weather Condition, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Weather condition values\n",
    "dataset['Weather Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding of weather conditions\n",
    "# Group up the weather categories that could belong together (such as \"thunderstorm with light rain\" and \"thunderstorm with heavy rain\")\n",
    "dataset['Weather_Rain'] = dataset['Weather Condition'].str.contains('rain').astype(bool)\n",
    "dataset['Weather_Thunderstorm'] = dataset['Weather Condition'].str.contains('thunderstorm').astype(bool)\n",
    "dataset['Weather_Fog'] = dataset['Weather Condition'].str.contains('fog').astype(bool)\n",
    "dataset['Weather_Mist'] = dataset['Weather Condition'].str.contains('mist').astype(bool)\n",
    "dataset['Weather_Snow'] = dataset['Weather Condition'].str.contains('snow').astype(bool)\n",
    "dataset['Weather_Drizzle'] = dataset['Weather Condition'].str.contains('drizzle').astype(bool)\n",
    "dataset['Weather_Haze'] = dataset['Weather Condition'].str.contains('haze').astype(bool)\n",
    "dataset['Weather_Clear'] = dataset['Weather Condition'].str.contains('clear').astype(bool)\n",
    "dataset['Weather_BrokenClouds'] = dataset['Weather Condition'].str.contains('broken clouds').astype(bool)\n",
    "dataset['Weather_FewClouds'] = dataset['Weather Condition'].str.contains('few clouds').astype(bool)\n",
    "dataset['Weather_OvercastClouds'] = dataset['Weather Condition'].str.contains('overcast clouds').astype(bool)\n",
    "dataset['Weather_ScatteredClouds'] = dataset['Weather Condition'].str.contains('scattered clouds').astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of the start_neighborhood feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of the start_neighborhood feature\n",
    "dataset['sn_Verdun'] = dataset['start_neighborhood'].str.contains('Verdun').astype(bool)\n",
    "dataset['sn_Le Plateau-Mont-Royal'] = dataset['start_neighborhood'].str.contains('Le Plateau-Mont-Royal').astype(bool)\n",
    "dataset['sn_Ville-Marie'] = dataset['start_neighborhood'].str.contains('Ville-Marie').astype(bool)\n",
    "dataset['sn_Côte-des-Neiges-Notre-Dame-de-Grâce'] = dataset['start_neighborhood'].str.contains('Côte-des-Neiges-Notre-Dame-de-Grâce').astype(bool)\n",
    "dataset['sn_Villeray-Saint-Michel-Parc-Extension'] = dataset['start_neighborhood'].str.contains('Villeray-Saint-Michel-Parc-Extension').astype(bool)\n",
    "dataset['sn_Rosemont-La Petite-Patrie'] = dataset['start_neighborhood'].str.contains('Rosemont-La Petite-Patrie').astype(bool)\n",
    "dataset['sn_Outremont'] = dataset['start_neighborhood'].str.contains('Outremont').astype(bool)\n",
    "dataset['sn_Le Sud-Ouest'] = dataset['start_neighborhood'].str.contains('Le Sud-Ouest').astype(bool)\n",
    "dataset['sn_Mercier-Hochelaga-Maisonneuve'] = dataset['start_neighborhood'].str.contains('Mercier-Hochelaga-Maisonneuve').astype(bool)\n",
    "dataset['sn_Westmount'] = dataset['start_neighborhood'].str.contains('Westmount').astype(bool)\n",
    "dataset['sn_Ahuntsic-Cartierville'] = dataset['start_neighborhood'].str.contains('Ahuntsic-Cartierville').astype(bool)\n",
    "dataset['sn_LaSalle'] = dataset['start_neighborhood'].str.contains('LaSalle').astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of route_affectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 64 categories, we need to split it in half, at least"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First: Transforming the variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['residentiel-residentiel', 'institution-institution',\n",
       "       'mixte-residentiel', ..., 'mixte-residentiel', 'mixte-parc',\n",
       "       'residentiel-institution'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['route_affectations'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to order values (start and end affectations) by alphabetical order, in order to reduce the multiplicity of values to a minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_route_affectations(value):\n",
    "    #Splitting the route affectations in two\n",
    "    affectations = value.split('-')\n",
    "    #Ordering the list by alphabetical order:\n",
    "    affectations.sort()\n",
    "    affectations = '-'.join(affectations)\n",
    "    return affectations\n",
    "dataset['route_affectations_ordered'] = dataset['route_affectations'].apply(reorder_route_affectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['route_affectations_ordered'] = dataset['route_affectations_ordered'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[residentiel-residentiel, institution-institution, mixte-residentiel, mixte-mixte, mixte-mixte, ..., mixte-mixte, residentiel-residentiel, mixte-residentiel, mixte-parc, institution-residentiel]\n",
       "Length: 4740357\n",
       "Categories (36, object): [activites diversifiees-activites diversifiees, activites diversifiees-emplois, activites diversifiees-institution, activites diversifiees-mixte, ..., parc-residentiel, religieux-religieux, religieux-residentiel, residentiel-residentiel]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['route_affectations_ordered'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have 36 values now, much better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we do the one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixte-residentiel                   value count: 1383263\n",
    "dataset['ra_mixte-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"mixte-residentiel\").astype(bool)\n",
    "#residentiel-residentiel                          1037211\n",
    "dataset['ra_residentiel-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"residentiel-residentiel\").astype(bool)\n",
    "#mixte-mixte                                       826508\n",
    "dataset['ra_mixte-mixte'] = dataset['route_affectations_ordered'].str.contains(\"residentiel-residentiel\").astype(bool)\n",
    "#institution-mixte                                 287514\n",
    "dataset['ra_institution-mixte'] = dataset['route_affectations_ordered'].str.contains(\"institution-mixte\").astype(bool)\n",
    "#institution-residentiel                           249713\n",
    "dataset['ra_institution-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"institution-residentiel\").astype(bool)\n",
    "#parc-residentiel                                  240312\n",
    "dataset['ra_parc-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"parc-residentiel\").astype(bool)\n",
    "#mixte-parc                                        237214\n",
    "dataset['ra_mixte-parc'] = dataset['route_affectations_ordered'].str.contains(\"mixte-parc\").astype(bool)\n",
    "#emplois-residentiel                                86356\n",
    "dataset['ra_emplois-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"emplois-residentiel\").astype(bool)\n",
    "#parc-parc                                          75962\n",
    "dataset['ra_parc-parc'] = dataset['route_affectations_ordered'].str.contains(\"parc-parc\").astype(bool)\n",
    "#mixte-nan                                          46232\n",
    "dataset['ra_mixte-nan'] = dataset['route_affectations_ordered'].str.contains(\"mixte-nan\").astype(bool)\n",
    "#institution-parc                                   44424\n",
    "dataset['ra_institution-parc'] = dataset['route_affectations_ordered'].str.contains(\"institution-parc\").astype(bool)\n",
    "#emplois-mixte                                      40057\n",
    "dataset['ra_emplois-mixte'] = dataset['route_affectations_ordered'].str.contains(\"emplois-mixte\").astype(bool)\n",
    "#activites diversifiees-residentiel                 33751\n",
    "dataset['ra_activitesdiversifiees-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-residentiel\").astype(bool)\n",
    "#institution-institution                            30830\n",
    "dataset['ra_institution-institution'] = dataset['route_affectations_ordered'].str.contains(\"institution-institution\").astype(bool)\n",
    "#nan-residentiel                                    30573\n",
    "dataset['ra_nan-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"nan-residentiel\").astype(bool)\n",
    "#activites diversifiees-mixte                       17004\n",
    "dataset['ra_activitesdiversifiees-mixte'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-mixte\").astype(bool)\n",
    "#mixte-religieux                                    11954\n",
    "dataset['ra_mixte-religieux'] = dataset['route_affectations_ordered'].str.contains(\"mixte-religieux\").astype(bool)\n",
    "#nan-nan                                             9033\n",
    "dataset['ra_nan-nan'] = dataset['route_affectations_ordered'].str.contains(\"nan-nan\").astype(bool)\n",
    "#institution-nan                                     8231\n",
    "dataset['ra_institution-nan'] = dataset['route_affectations_ordered'].str.contains(\"institution-nan\").astype(bool)\n",
    "#emplois-institution                                 7962\n",
    "dataset['ra_emplois-institution'] = dataset['route_affectations_ordered'].str.contains(\"emplois-institution\").astype(bool)\n",
    "#emplois-parc                                        5829\n",
    "dataset['ra_emplois-parc'] = dataset['route_affectations_ordered'].str.contains(\"emplois-parc\").astype(bool)\n",
    "#emplois-emplois                                     5545\n",
    "dataset['ra_emplois-emplois'] = dataset['route_affectations_ordered'].str.contains(\"emplois-emplois\").astype(bool)\n",
    "#religieux-residentiel                               4371\n",
    "dataset['ra_religieux-residentiel'] = dataset['route_affectations_ordered'].str.contains(\"religieux-residentiel\").astype(bool)\n",
    "#activites diversifiees-parc                         3544\n",
    "dataset['ra_activites diversifiees-parc'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-parc\").astype(bool)\n",
    "#nan-parc                                            3438\n",
    "dataset['ra_nan-parc'] = dataset['route_affectations_ordered'].str.contains(\"nan-parc\").astype(bool)\n",
    "#institution-religieux                               2944\n",
    "dataset['ra_institution-religieux'] = dataset['route_affectations_ordered'].str.contains(\"institution-religieux\").astype(bool)\n",
    "#activites diversifiees-institution                  2600\n",
    "dataset['ra_activitesdiversifiees-institution'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-institution\").astype(bool)\n",
    "#activites diversifiees-emplois                      2453\n",
    "dataset['ra_activitesdiversifiees-emplois'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-emplois\").astype(bool)\n",
    "#nan-religieux                                       1504\n",
    "dataset['ra_nan-religieux'] = dataset['route_affectations_ordered'].str.contains(\"nan-religieux\").astype(bool)\n",
    "#activites diversifiees-activites diversifiees       1174\n",
    "dataset['ra_activitesdiversifiees-activitesdiversifiees'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-activites diversifiees\").astype(bool)\n",
    "#emplois-nan                                         1160\n",
    "dataset['ra_emplois-nan'] = dataset['route_affectations_ordered'].str.contains(\"emplois-nan\").astype(bool)\n",
    "#parc-religieux                                       631\n",
    "dataset['ra_parc-religieux'] = dataset['route_affectations_ordered'].str.contains(\"parc-religieux\").astype(bool)\n",
    "#activites diversifiees-nan                           609\n",
    "dataset['ra_activitesdiversifiees-nan'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-nan\").astype(bool)\n",
    "#religieux-religieux                                  345\n",
    "dataset['ra_religieux-religieux'] = dataset['route_affectations_ordered'].str.contains(\"religieux-religieux\").astype(bool)\n",
    "#activites diversifiees-religieux                      62\n",
    "dataset['ra_activitesdiversifiees-religieux'] = dataset['route_affectations_ordered'].str.contains(\"activites diversifiees-religieux\").astype(bool)\n",
    "#emplois-religieux                                     44\n",
    "dataset['ra_emplois-religieux'] = dataset['route_affectations_ordered'].str.contains(\"emplois-religieux\").astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second type of one-hot encoding: this time checking if only one of the stations belong to a perticular affectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ra2_mixte'] = dataset['route_affectations_ordered'].str.contains(\"mixte\").astype(bool)\n",
    "dataset['ra2_emplois'] = dataset['route_affectations_ordered'].str.contains(\"emplois\").astype(bool)\n",
    "dataset['ra2_religieux'] = dataset['route_affectations_ordered'].str.contains(\"religieux\").astype(bool)\n",
    "dataset['ra2_activitediversifiees'] = dataset['route_affectations_ordered'].str.contains(\"activite diversifiees\").astype(bool)\n",
    "dataset['ra2_nan'] = dataset['route_affectations_ordered'].str.contains(\"nan\").astype(bool)\n",
    "dataset['ra2_institution'] = dataset['route_affectations_ordered'].str.contains(\"institution\").astype(bool)\n",
    "dataset['ra2_parc'] = dataset['route_affectations_ordered'].str.contains(\"parc\").astype(bool)\n",
    "dataset['ra2_residentiel'] = dataset['route_affectations_ordered'].str.contains(\"residentiel\").astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of the start_weekday feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['swd_Monday'] = dataset['start_weekday'] == 0\n",
    "dataset['swd_Tuesday'] = dataset['start_weekday'] == 1\n",
    "dataset['swd_Wednesday'] = dataset['start_weekday'] == 2\n",
    "dataset['swd_Thursday'] = dataset['start_weekday'] == 3\n",
    "dataset['swd_Friday'] = dataset['start_weekday'] == 4\n",
    "dataset['swd_Saturday'] = dataset['start_weekday'] == 5\n",
    "dataset['swd_Sunday'] = dataset['start_weekday'] == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of the start_month feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sm_April'] = dataset['start_month'] == 4\n",
    "dataset['sm_May'] = dataset['start_month'] == 5\n",
    "dataset['sm_June'] = dataset['start_month'] == 6\n",
    "dataset['sm_July'] = dataset['start_month'] == 7\n",
    "dataset['sm_August'] = dataset['start_month'] == 8\n",
    "dataset['sm_September'] = dataset['start_month'] == 9\n",
    "dataset['sm_October'] = dataset['start_month'] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Data Types of Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['start_code'] = dataset['start_code'].astype('category')\n",
    "dataset['end_code'] = dataset['end_code'].astype('category')\n",
    "dataset['Weather Condition'] = dataset['Weather Condition'].astype('category')\n",
    "dataset['start_neighborhood'] = dataset['start_neighborhood'].astype('category')\n",
    "dataset['start_affectation'] = dataset['start_affectation'].astype('category')\n",
    "dataset['end_neighborhood'] = dataset['end_neighborhood'].astype('category')\n",
    "dataset['end_affectation'] = dataset['end_affectation'].astype('category')\n",
    "dataset['route_neighborhood'] = dataset['route_neighborhood'].astype('category')\n",
    "dataset['route_affectations'] = dataset['route_affectations'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['start_code_cat'] = dataset['start_code'].cat.codes\n",
    "dataset['end_code_cat'] = dataset['end_code'].cat.codes\n",
    "dataset['Weather Condition_cat'] = dataset['Weather Condition'].cat.codes\n",
    "dataset['start_neighborhood_cat'] = dataset['start_neighborhood'].cat.codes\n",
    "dataset['start_affectation_cat'] = dataset['start_affectation'].cat.codes\n",
    "dataset['end_neighborhood_cat'] = dataset['end_neighborhood'].cat.codes\n",
    "dataset['end_affectation_cat'] = dataset['end_affectation'].cat.codes\n",
    "dataset['route_neighborhood_cat'] = dataset['route_neighborhood'].cat.codes\n",
    "dataset['route_affectations_cat'] = dataset['route_affectations'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_date                        0\n",
       "end_date                          0\n",
       "duration_sec                      0\n",
       "is_member                         0\n",
       "start_code                        0\n",
       "start_name                        0\n",
       "start_latitude                    0\n",
       "start_longitude                   0\n",
       "start_neighborhood             4867\n",
       "start_great_park            4676037\n",
       "start_affectation             55051\n",
       "end_code                          0\n",
       "end_name                          0\n",
       "end_latitude                      0\n",
       "end_longitude                     0\n",
       "end_neighborhood               5772\n",
       "end_great_park              4683559\n",
       "end_affectation               54762\n",
       "start_date_hour                   0\n",
       "end_date_hour                     0\n",
       "Weather Condition                 0\n",
       "Humidity                          0\n",
       "Pressure                          0\n",
       "Wind Speed                        0\n",
       "Temperature                       0\n",
       "festivial_name_1            4739964\n",
       "festival1_lat               4739964\n",
       "festival1_long              4739964\n",
       "festival_name_2             4740251\n",
       "festival2_lat               4740251\n",
       "                             ...   \n",
       "ra2_emplois                       0\n",
       "ra2_religieux                     0\n",
       "ra2_activitediversifiees          0\n",
       "ra2_nan                           0\n",
       "ra2_institution                   0\n",
       "ra2_parc                          0\n",
       "ra2_residentiel                   0\n",
       "swd_Monday                        0\n",
       "swd_Tuesday                       0\n",
       "swd_Wednesday                     0\n",
       "swd_Thursday                      0\n",
       "swd_Friday                        0\n",
       "swd_Saturday                      0\n",
       "swd_Sunday                        0\n",
       "sm_April                          0\n",
       "sm_May                            0\n",
       "sm_June                           0\n",
       "sm_July                           0\n",
       "sm_August                         0\n",
       "sm_September                      0\n",
       "sm_October                        0\n",
       "start_code_cat                    0\n",
       "end_code_cat                      0\n",
       "Weather Condition_cat             0\n",
       "start_neighborhood_cat            0\n",
       "start_affectation_cat             0\n",
       "end_neighborhood_cat              0\n",
       "end_affectation_cat               0\n",
       "route_neighborhood_cat            0\n",
       "route_affectations_cat            0\n",
       "Length: 144, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out which columns contain missing values\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing empty values and fixing 'has_festival'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values with False:'no festival'\n",
    "dataset['has_festival'].fillna(value=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing '0' values for 'has_festival' : turning them into 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_has_festival(value):\n",
    "    if value == 0 or value == False:\n",
    "        return False\n",
    "    elif value == 1 or value == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "dataset['has_festival'] = dataset['has_festival'].apply(fix_has_festival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['has_festival'] = dataset['has_festival'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing empty values and fixing 'statutory holiday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import festival data - we need to fix statutory holiday\n",
    "festival = pd.read_csv(\"Data/Festival/csv_dataset_holiday_festival.csv\", parse_dates=['date'], encoding = \"gb2312\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "festival = festival.filter(axis=1, items=['date','statutory_holiday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "festival['statutory_holiday'] = festival['statutory_holiday'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1609\n",
       "True       60\n",
       "Name: statutory_holiday, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "festival['statutory_holiday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears fixed now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the festival data with the dataset\n",
    "dataset = dataset.merge(festival, how='left', left_on='start_date', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['start_date', 'end_date', 'duration_sec', 'is_member', 'start_code',\n",
       "       'start_name', 'start_latitude', 'start_longitude', 'start_neighborhood',\n",
       "       'start_great_park',\n",
       "       ...\n",
       "       'end_code_cat', 'Weather Condition_cat', 'start_neighborhood_cat',\n",
       "       'start_affectation_cat', 'end_neighborhood_cat', 'end_affectation_cat',\n",
       "       'route_neighborhood_cat', 'route_affectations_cat', 'date',\n",
       "       'statutory_holiday_y'],\n",
       "      dtype='object', length=146)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(axis=1,columns=['statutory_holiday_x', 'date'],inplace=True)\n",
    "dataset.rename({'statutory_holiday_y':'statutory_holiday'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['start_date', 'end_date', 'duration_sec', 'is_member', 'start_code',\n",
       "       'start_name', 'start_latitude', 'start_longitude', 'start_neighborhood',\n",
       "       'start_great_park',\n",
       "       ...\n",
       "       'start_code_cat', 'end_code_cat', 'Weather Condition_cat',\n",
       "       'start_neighborhood_cat', 'start_affectation_cat',\n",
       "       'end_neighborhood_cat', 'end_affectation_cat', 'route_neighborhood_cat',\n",
       "       'route_affectations_cat', 'statutory_holiday'],\n",
       "      dtype='object', length=144)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'statutory_holiday' appears fixed as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing festival dataset from memory\n",
    "del festival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4740357, 144)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4740357 entries, 0 to 4740356\n",
      "Columns: 144 entries, start_date to statutory_holiday\n",
      "dtypes: bool(84), category(10), datetime64[ns](4), float64(13), int16(3), int64(12), int8(6), object(12)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing category variables back to object, as they cannot be stored this way in HDF format.\n",
    "dataset['start_code'] = dataset['start_code'].astype('object')\n",
    "dataset['end_code'] = dataset['end_code'].astype('object')\n",
    "dataset['Weather Condition'] = dataset['Weather Condition'].astype('object')\n",
    "dataset['start_neighborhood'] = dataset['start_neighborhood'].astype('object')\n",
    "dataset['start_affectation'] = dataset['start_affectation'].astype('object')\n",
    "dataset['end_neighborhood'] = dataset['end_neighborhood'].astype('object')\n",
    "dataset['end_affectation'] = dataset['end_affectation'].astype('object')\n",
    "dataset['route_neighborhood'] = dataset['route_neighborhood'].astype('object')\n",
    "dataset['route_affectations'] = dataset['route_affectations'].astype('object')\n",
    "dataset['route_affectations_ordered'] = dataset['route_affectations_ordered'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the modified dataset to disk\n",
    "dataset.to_hdf(\"/Users/gabriel/dataset_2017_final.hdf\",key=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bixi_Modeling.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
